{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn \n",
    "# Components\n",
    "from surprise import similarities as sims\n",
    "from surprise.prediction_algorithms.optimize_baselines import baseline_als, baseline_sgd\n",
    "# Datastructure\n",
    "import heapq\n",
    "# Models\n",
    "from surprise import SVD\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton\n",
    "class AlgoBase:\n",
    "    \"\"\"\n",
    "    Keyword Args:\n",
    "        baseline_options(dict, optional): If the algorithm needs to compute a\n",
    "            baseline estimate, the ``baseline_options`` parameter is used to\n",
    "            configure how they are computed. See\n",
    "            :ref:`baseline_estimates_configuration` for usage.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.bsl_options = kwargs.get(\"bsl_options\", {})\n",
    "        self.sim_options = kwargs.get(\"sim_options\", {})\n",
    "        if \"user_based\" not in self.sim_options:\n",
    "            self.sim_options[\"user_based\"] = True\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        \"\"\"Initializes some internal structures and set the self.trainset attribute.\n",
    "        Args:\n",
    "            trainset(:obj:`Trainset <surprise.Trainset>`) : A training\n",
    "                set, as returned by the :meth:`folds\n",
    "                <surprise.dataset.Dataset.folds>` method.\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.trainset = trainset\n",
    "\n",
    "        # (re) Initialise baselines\n",
    "        self.bu = self.bi = None\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, uid, iid, r_ui=None,rough=False, clip=True,  verbose=False):\n",
    "        \"\"\"Compute the rating prediction for given user and item.\n",
    "\n",
    "        The ``predict`` method converts raw ids to inner ids and then calls the\n",
    "        ``estimate`` method which is defined in every derived class. If the\n",
    "        prediction is impossible (e.g. because the user and/or the item is\n",
    "        unknown), the prediction is set according to\n",
    "        :meth:`default_prediction()\n",
    "        <surprise.prediction_algorithms.algo_base.AlgoBase.default_prediction>`.\n",
    "\n",
    "        Args:\n",
    "            uid: (Raw) id of the user. See :ref:`this note<raw_inner_note>`.\n",
    "            iid: (Raw) id of the item. See :ref:`this note<raw_inner_note>`.\n",
    "            r_ui(float): The true rating :math:`r_{ui}`. Optional, default is\n",
    "                ``None``.\n",
    "            clip(bool): Whether to clip the estimation into the rating scale.\n",
    "                For example, if :math:`\\\\hat{r}_{ui}` is :math:`5.5` while the\n",
    "                rating scale is :math:`[1, 5]`, then :math:`\\\\hat{r}_{ui}` is\n",
    "                set to :math:`5`. Same goes if :math:`\\\\hat{r}_{ui} < 1`.\n",
    "                Default is ``True``.\n",
    "            verbose(bool): Whether to print details of the prediction.  Default\n",
    "                is False.\n",
    "\n",
    "        Returns:\n",
    "            A :obj:`Prediction\\\n",
    "            <surprise.prediction_algorithms.predictions.Prediction>` object\n",
    "            containing:\n",
    "\n",
    "            - The (raw) user id ``uid``.\n",
    "            - The (raw) item id ``iid``.\n",
    "            - The true rating ``r_ui`` (:math:`r_{ui}`).\n",
    "            - The estimated rating (:math:`\\\\hat{r}_{ui}`).\n",
    "            - Some additional details about the prediction that might be useful\n",
    "              for later analysis.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert raw ids to inner ids\n",
    "        try:\n",
    "            iuid = self.trainset.to_inner_uid(uid)\n",
    "        except ValueError:\n",
    "            iuid = \"UKN__\" + str(uid)\n",
    "        try:\n",
    "            iiid = self.trainset.to_inner_iid(iid)\n",
    "        except ValueError:\n",
    "            iiid = \"UKN__\" + str(iid)\n",
    "\n",
    "        details = {}\n",
    "        try:\n",
    "            est, details, similarity, neighbors = self.estimate(iuid, iiid)\n",
    "\n",
    "            details[\"was_impossible\"] = False\n",
    "\n",
    "        except PredictionImpossible as e:\n",
    "            est,similarity, neighbors = self.default_prediction(rough) # !\n",
    "            details[\"was_impossible\"] = True\n",
    "            details[\"reason\"] = str(e)\n",
    "        # clip estimate into [lower_bound, higher_bound]\n",
    "        if clip:\n",
    "            # lower_bound, higher_bound = self.trainset.rating_scale\n",
    "            lower_bound, higher_bound = 0,5\n",
    "            est = min(higher_bound, est)\n",
    "            est = max(lower_bound, est)\n",
    "\n",
    "        pred = Prediction(uid, iid, r_ui, est, details)\n",
    "\n",
    "        if verbose:\n",
    "            print(pred)\n",
    "\n",
    "        return pred, similarity, neighbors\n",
    "\n",
    "    def default_prediction(self, rough):\n",
    "        \"\"\"Used when the ``PredictionImpossible`` exception is raised during a\n",
    "        call to :meth:`predict()\n",
    "        <surprise.prediction_algorithms.algo_base.AlgoBase.predict>`. By\n",
    "        default, return the global mean of all ratings (can be overridden in\n",
    "        child classes).\n",
    "\n",
    "        Returns:\n",
    "            (float): The mean of all ratings in the trainset.\n",
    "        \"\"\"\n",
    "        dePred = self.trainset.global_mean\n",
    "        return dePred, -1, -1\n",
    "\n",
    "\n",
    "    def test(self, testset, rough,verbose=False):\n",
    "        \"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\n",
    "        in the given testset.\n",
    "\n",
    "        Args:\n",
    "            testset: A test set, as returned by a :ref:`cross-validation\n",
    "                itertor<use_cross_validation_iterators>` or by the\n",
    "                :meth:`build_testset() <surprise.Trainset.build_testset>`\n",
    "                method.\n",
    "            verbose(bool): Whether to print details for each predictions.\n",
    "                Default is False.\n",
    "\n",
    "        Returns:\n",
    "            A list of :class:`Prediction\\\n",
    "            <surprise.prediction_algorithms.predictions.Prediction>` objects\n",
    "            that contains all the estimated ratings.\n",
    "        \"\"\"\n",
    "\n",
    "        # The ratings are translated back to their original scale.\n",
    "        predictions = []\n",
    "        for (uid, iid, r_ui_trans) in testset:\n",
    "            pred, similarity, neighbors = self.predict(uid, iid, r_ui_trans,rough, verbose=verbose)\n",
    "            predictions.append((pred.uid, pred.iid, pred.est, similarity, neighbors))\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def compute_baselines(self):\n",
    "        \"\"\"Compute users and items baselines.\n",
    "\n",
    "        The way baselines are computed depends on the ``bsl_options`` parameter\n",
    "        passed at the creation of the algorithm (see\n",
    "        :ref:`baseline_estimates_configuration`).\n",
    "\n",
    "        This method is only relevant for algorithms using :func:`Pearson\n",
    "        baseline similarity<surprise.similarities.pearson_baseline>` or the\n",
    "        :class:`BaselineOnly\n",
    "        <surprise.prediction_algorithms.baseline_only.BaselineOnly>` algorithm.\n",
    "\n",
    "        Returns:\n",
    "            A tuple ``(bu, bi)``, which are users and items baselines.\"\"\"\n",
    "\n",
    "        # Firt of, if this method has already been called before on the same\n",
    "        # trainset, then just return. Indeed, compute_baselines may be called\n",
    "        # more than one time, for example when a similarity metric (e.g.\n",
    "        # pearson_baseline) uses baseline estimates.\n",
    "        if self.bu is not None:\n",
    "            return self.bu, self.bi\n",
    "\n",
    "        method = dict(als=baseline_als, sgd=baseline_sgd)\n",
    "\n",
    "        method_name = self.bsl_options.get(\"method\", \"als\")\n",
    "\n",
    "        try:\n",
    "            if getattr(self, \"verbose\", False):\n",
    "                print(\"Estimating biases using\", method_name + \"...\")\n",
    "            self.bu, self.bi = method[method_name](self)\n",
    "            return self.bu, self.bi\n",
    "        except KeyError:\n",
    "            raise ValueError(\n",
    "                \"Invalid method \"\n",
    "                + method_name\n",
    "                + \" for baseline computation.\"\n",
    "                + \" Available methods are als and sgd.\"\n",
    "            )\n",
    "\n",
    "\n",
    "    def compute_similarities(self):\n",
    "        \"\"\"Build the similarity matrix.\n",
    "\n",
    "        The way the similarity matrix is computed depends on the\n",
    "        ``sim_options`` parameter passed at the creation of the algorithm (see\n",
    "        :ref:`similarity_measures_configuration`).\n",
    "\n",
    "        This method is only relevant for algorithms using a similarity measure,\n",
    "        such as the :ref:`k-NN algorithms <pred_package_knn_inpired>`.\n",
    "\n",
    "        Returns:\n",
    "            The similarity matrix.\"\"\"\n",
    "\n",
    "        construction_func = {\n",
    "            \"cosine\": sims.cosine,\n",
    "            \"msd\": sims.msd,\n",
    "            \"pearson\": sims.pearson,\n",
    "            \"pearson_baseline\": sims.pearson_baseline,\n",
    "        }\n",
    "\n",
    "        if self.sim_options[\"user_based\"]:\n",
    "            n_x, yr = self.trainset.n_users, self.trainset.ir\n",
    "        else:\n",
    "            n_x, yr = self.trainset.n_items, self.trainset.ur\n",
    "\n",
    "        min_support = self.sim_options.get(\"min_support\", 1)\n",
    "\n",
    "        args = [n_x, yr, min_support]\n",
    "\n",
    "        name = self.sim_options.get(\"name\", \"msd\").lower()\n",
    "        if name == \"pearson_baseline\":\n",
    "            shrinkage = self.sim_options.get(\"shrinkage\", 100)\n",
    "            bu, bi = self.compute_baselines()\n",
    "            if self.sim_options[\"user_based\"]:\n",
    "                bx, by = bu, bi\n",
    "            else:\n",
    "                bx, by = bi, bu\n",
    "\n",
    "            args += [self.trainset.global_mean, bx, by, shrinkage]\n",
    "\n",
    "        try:\n",
    "            if getattr(self, \"verbose\", False):\n",
    "                print(f\"Computing the {name} similarity matrix...\")\n",
    "            sim = construction_func[name](*args)\n",
    "            if getattr(self, \"verbose\", False):\n",
    "                print(\"Done computing similarity matrix.\")\n",
    "            return sim\n",
    "        except KeyError:\n",
    "            raise NameError(\n",
    "                \"Wrong sim name \"\n",
    "                + name\n",
    "                + \". Allowed values \"\n",
    "                + \"are \"\n",
    "                + \", \".join(construction_func.keys())\n",
    "                + \".\"\n",
    "            )\n",
    "\n",
    "\n",
    "    def get_neighbors(self, iid, k):\n",
    "        \"\"\"Return the ``k`` nearest neighbors of ``iid``, which is the inner id\n",
    "        of a user or an item, depending on the ``user_based`` field of\n",
    "        ``sim_options`` (see :ref:`similarity_measures_configuration`).\n",
    "\n",
    "        As the similarities are computed on the basis of a similarity measure,\n",
    "        this method is only relevant for algorithms using a similarity measure,\n",
    "        such as the :ref:`k-NN algorithms <pred_package_knn_inpired>`.\n",
    "\n",
    "        For a usage example, see the :ref:`FAQ <get_k_nearest_neighbors>`.\n",
    "\n",
    "        Args:\n",
    "            iid(int): The (inner) id of the user (or item) for which we want\n",
    "                the nearest neighbors. See :ref:`this note<raw_inner_note>`.\n",
    "\n",
    "            k(int): The number of neighbors to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            The list of the ``k`` (inner) ids of the closest users (or items)\n",
    "            to ``iid``.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.sim_options[\"user_based\"]:\n",
    "            all_instances = self.trainset.all_users\n",
    "        else:\n",
    "            all_instances = self.trainset.all_items\n",
    "        others = [(x, self.sim[iid, x]) for x in all_instances() if x != iid]\n",
    "        others = heapq.nlargest(k, others, key=lambda tple: tple[1])\n",
    "        k_nearest_neighbors = [j for (j, _) in others]\n",
    "\n",
    "        return k_nearest_neighbors\n",
    "\n",
    "class SymmetricAlgo(AlgoBase):\n",
    "    \"\"\"This is an abstract class aimed to ease the use of symmetric algorithms.\n",
    "\n",
    "    A symmetric algorithm is an algorithm that can can be based on users or on\n",
    "    items indifferently, e.g. all the algorithms in this module.\n",
    "\n",
    "    When the algo is user-based x denotes a user and y an item. Else, it's\n",
    "    reversed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sim_options={}, verbose=True, **kwargs):\n",
    "        AlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        ub = self.sim_options[\"user_based\"]\n",
    "        self.n_x = self.trainset.n_users if ub else self.trainset.n_items\n",
    "        self.n_y = self.trainset.n_items if ub else self.trainset.n_users\n",
    "        self.xr = self.trainset.ur if ub else self.trainset.ir\n",
    "        self.yr = self.trainset.ir if ub else self.trainset.ur\n",
    "\n",
    "        return self\n",
    "\n",
    "    def switch(self, u_stuff, i_stuff):\n",
    "        \"\"\"Return x_stuff and y_stuff depending on the user_based field.\"\"\"\n",
    "\n",
    "        if self.sim_options[\"user_based\"]:\n",
    "            return u_stuff, i_stuff\n",
    "        else:\n",
    "            return i_stuff, u_stuff\n",
    "\n",
    "# Prediction Module\n",
    "class PredictionImpossible(Exception):\n",
    "    r\"\"\"Exception raised when a prediction is impossible.\n",
    "\n",
    "    When raised, the estimation :math:`\\hat{r}_{ui}` is set to the global mean\n",
    "    of all ratings :math:`\\mu`.\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "class Prediction(namedtuple(\"Prediction\", [\"uid\", \"iid\", \"r_ui\", \"est\", \"details\"])):\n",
    "    \"\"\"A named tuple for storing the results of a prediction.\n",
    "\n",
    "    It's wrapped in a class, but only for documentation and printing purposes.\n",
    "\n",
    "    Args:\n",
    "        uid: The (raw) user id. See :ref:`this note<raw_inner_note>`.\n",
    "        iid: The (raw) item id. See :ref:`this note<raw_inner_note>`.\n",
    "        r_ui(float): The true rating :math:`r_{ui}`.\n",
    "        est(float): The estimated rating :math:`\\\\hat{r}_{ui}`.\n",
    "        details (dict): Stores additional details about the prediction that\n",
    "            might be useful for later analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = ()  # for memory saving purpose.\n",
    "\n",
    "    def __str__(self):\n",
    "        s = f\"user: {self.uid:<10} \"\n",
    "        s += f\"item: {self.iid:<10} \"\n",
    "        if self.r_ui is not None:\n",
    "            s += f\"r_ui = {self.r_ui:1.2f}   \"\n",
    "        else:\n",
    "            s += \"r_ui = None   \"\n",
    "        s += f\"est = {self.est:1.2f}   \"\n",
    "        s += str(self.details)\n",
    "\n",
    "        return s\n",
    "\n",
    "def needed_pred_size(trainset, ratio):\n",
    "    u = trainset.n_users\n",
    "    i = trainset.n_items\n",
    "    filled = trainset.n_ratings\n",
    "    result = int(np.ceil(u*i*ratio - filled))\n",
    "    # result = int(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNBasic(SymmetricAlgo):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        k(int): The (max) number of neighbors to take into account for\n",
    "            aggregation (see :ref:`this note <actual_k_note>`). Default is\n",
    "            ``40``.\n",
    "        min_k(int): The minimum number of neighbors to take into account for\n",
    "            aggregation. If there are not enough neighbors, the prediction is\n",
    "            set to the global mean of all ratings. Default is ``1``.\n",
    "        sim_options(dict): A dictionary of options for the similarity\n",
    "            measure. See :ref:`similarity_measures_configuration` for accepted\n",
    "            options.\n",
    "        verbose(bool): Whether to print trace messages of bias estimation,\n",
    "            similarity, etc.  Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=40, min_k=1, sim_options={}, verbose=True, **kwargs):\n",
    "\n",
    "        SymmetricAlgo.__init__(self, sim_options=sim_options, verbose=verbose, **kwargs)\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "\n",
    "    def fit(self, trainset): # Extract basic info and compute similarity\n",
    "        SymmetricAlgo.fit(self, trainset)\n",
    "        self.sim = self.compute_similarities()\n",
    "        print(\"Similarity matrix:\",np.shape(self.sim))\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i): \n",
    "\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible(\"User and/or item is unknown.\")\n",
    "\n",
    "        x, y = self.switch(u, i)\n",
    "\n",
    "        neighbors = [(self.sim[x, x2], r) for (x2, r) in self.yr[y]]\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
    "\n",
    "        # compute weighted average\n",
    "        sum_sim = sum_ratings = actual_k = 0\n",
    "        for (sim, r) in k_neighbors:\n",
    "            if sim > 0:\n",
    "                sum_sim += sim\n",
    "                sum_ratings += sim * r\n",
    "                actual_k += 1\n",
    "        if actual_k < self.min_k:\n",
    "            raise PredictionImpossible(\"Not enough neighbors.\")\n",
    "        # truncation mechanism\n",
    "        est = sum_ratings / sum_sim\n",
    "        details = {\"actual_k\": actual_k}\n",
    "        return est, details, sum_sim/actual_k, actual_k\n",
    "    \n",
    "class KNNWithMeans(SymmetricAlgo):\n",
    "    \"\"\"A basic collaborative filtering algorithm, taking into account the mean\n",
    "    ratings of each user.\n",
    "    Args:\n",
    "        k(int): The (max) number of neighbors to take into account for\n",
    "            aggregation (see :ref:`this note <actual_k_note>`). Default is\n",
    "            ``40``.\n",
    "        min_k(int): The minimum number of neighbors to take into account for\n",
    "            aggregation. If there are not enough neighbors, the neighbor\n",
    "            aggregation is set to zero (so the prediction ends up being\n",
    "            equivalent to the mean :math:`\\\\mu_u` or :math:`\\\\mu_i`). Default is\n",
    "            ``1``.\n",
    "        sim_options(dict): A dictionary of options for the similarity\n",
    "            measure. See :ref:`similarity_measures_configuration` for accepted\n",
    "            options.\n",
    "        verbose(bool): Whether to print trace messages of bias estimation,\n",
    "            similarity, etc.  Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=40, min_k=1, sim_options={}, verbose=True, **kwargs):\n",
    "\n",
    "        SymmetricAlgo.__init__(self, sim_options=sim_options, verbose=verbose, **kwargs)\n",
    "\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        SymmetricAlgo.fit(self, trainset)\n",
    "        self.sim = self.compute_similarities()\n",
    "\n",
    "        self.means = np.zeros(self.n_x)\n",
    "        for x, ratings in self.xr.items():\n",
    "            self.means[x] = np.mean([r for (_, r) in ratings])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible(\"User and/or item is unknown.\")\n",
    "\n",
    "        x, y = self.switch(u, i)\n",
    "\n",
    "        neighbors = [(x2, self.sim[x, x2], r) for (x2, r) in self.yr[y]]\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[1])\n",
    "\n",
    "        est = self.means[x]\n",
    "\n",
    "        # compute weighted average\n",
    "        sum_sim = sum_ratings = actual_k = 0\n",
    "        for (nb, sim, r) in k_neighbors:\n",
    "            if sim > 0:\n",
    "                sum_sim += sim\n",
    "                sum_ratings += sim * (r - self.means[nb])\n",
    "                actual_k += 1\n",
    "\n",
    "        if actual_k < self.min_k:\n",
    "            sum_ratings = 0\n",
    "\n",
    "        try:\n",
    "            est += sum_ratings / sum_sim\n",
    "        except ZeroDivisionError:\n",
    "            pass  # return mean\n",
    "\n",
    "        details = {\"actual_k\": actual_k}\n",
    "        if actual_k == 0:\n",
    "            return est, details, -1, -1\n",
    "        else: \n",
    "            return est, details, sum_sim/actual_k, actual_k\n",
    "         \n",
    "class KNNBaseline(SymmetricAlgo):\n",
    "    \"\"\"A basic collaborative filtering algorithm taking into account a\n",
    "    *baseline* rating.\n",
    "\n",
    "\n",
    "    The prediction :math:`\\\\hat{r}_{ui}` is set as:\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{r}_{ui} = b_{ui} + \\\\frac{ \\\\sum\\\\limits_{v \\\\in N^k_i(u)}\n",
    "        \\\\text{sim}(u, v) \\\\cdot (r_{vi} - b_{vi})} {\\\\sum\\\\limits_{v \\\\in\n",
    "        N^k_i(u)} \\\\text{sim}(u, v)}\n",
    "\n",
    "    or\n",
    "\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{r}_{ui} = b_{ui} + \\\\frac{ \\\\sum\\\\limits_{j \\\\in N^k_u(i)}\n",
    "        \\\\text{sim}(i, j) \\\\cdot (r_{uj} - b_{uj})} {\\\\sum\\\\limits_{j \\\\in\n",
    "        N^k_u(i)} \\\\text{sim}(i, j)}\n",
    "\n",
    "    depending on the ``user_based`` field of the ``sim_options`` parameter. For\n",
    "    the best predictions, use the :func:`pearson_baseline\n",
    "    <surprise.similarities.pearson_baseline>` similarity measure.\n",
    "\n",
    "    This algorithm corresponds to formula (3), section 2.2 of\n",
    "    :cite:`Koren:2010`.\n",
    "\n",
    "    Args:\n",
    "        k(int): The (max) number of neighbors to take into account for\n",
    "            aggregation (see :ref:`this note <actual_k_note>`). Default is\n",
    "            ``40``.\n",
    "        min_k(int): The minimum number of neighbors to take into account for\n",
    "            aggregation. If there are not enough neighbors, the neighbor\n",
    "            aggregation is set to zero (so the prediction ends up being\n",
    "            equivalent to the baseline). Default is ``1``.\n",
    "        sim_options(dict): A dictionary of options for the similarity\n",
    "            measure. See :ref:`similarity_measures_configuration` for accepted\n",
    "            options. It is recommended to use the :func:`pearson_baseline\n",
    "            <surprise.similarities.pearson_baseline>` similarity measure.\n",
    "\n",
    "        bsl_options(dict): A dictionary of options for the baseline estimates\n",
    "            computation. See :ref:`baseline_estimates_configuration` for\n",
    "            accepted options.\n",
    "        verbose(bool): Whether to print trace messages of bias estimation,\n",
    "            similarity, etc.  Default is True.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, k=40, min_k=1, sim_options={}, bsl_options={}, verbose=True, **kwargs\n",
    "    ):\n",
    "\n",
    "        SymmetricAlgo.__init__(\n",
    "            self,\n",
    "            sim_options=sim_options,\n",
    "            bsl_options=bsl_options,\n",
    "            verbose=verbose,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        SymmetricAlgo.fit(self, trainset)\n",
    "        self.bu, self.bi = self.compute_baselines()\n",
    "        self.bx, self.by = self.switch(self.bu, self.bi)\n",
    "        self.sim = self.compute_similarities()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        est = self.trainset.global_mean\n",
    "        if self.trainset.knows_user(u):\n",
    "            est += self.bu[u]\n",
    "        if self.trainset.knows_item(i):\n",
    "            est += self.bi[i]\n",
    "\n",
    "        x, y = self.switch(u, i)\n",
    "\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            return est\n",
    "\n",
    "        neighbors = [(x2, self.sim[x, x2], r) for (x2, r) in self.yr[y]]\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[1])\n",
    "\n",
    "        # compute weighted average\n",
    "        sum_sim = sum_ratings = actual_k = 0\n",
    "        for (nb, sim, r) in k_neighbors:\n",
    "            if sim > 0:\n",
    "                sum_sim += sim\n",
    "                nb_bsl = self.trainset.global_mean + self.bx[nb] + self.by[y]\n",
    "                sum_ratings += sim * (r - nb_bsl)\n",
    "                actual_k += 1\n",
    "\n",
    "        if actual_k < self.min_k:\n",
    "            sum_ratings = 0\n",
    "\n",
    "        try:\n",
    "            est += sum_ratings / sum_sim\n",
    "        except ZeroDivisionError:\n",
    "            pass  # just baseline again\n",
    "\n",
    "        details = {\"actual_k\": actual_k}\n",
    "        if actual_k == 0:\n",
    "            return est, details, -1, -1\n",
    "        else: \n",
    "            return est, details, sum_sim/actual_k, actual_k\n",
    "   \n",
    "class KNNWithZScore(SymmetricAlgo):\n",
    "    \"\"\"A basic collaborative filtering algorithm, taking into account\n",
    "    the z-score normalization of each user.\n",
    "\n",
    "    The prediction :math:`\\\\hat{r}_{ui}` is set as:\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{r}_{ui} = \\\\mu_u + \\\\sigma_u \\\\frac{ \\\\sum\\\\limits_{v \\\\in N^k_i(u)}\n",
    "        \\\\text{sim}(u, v) \\\\cdot (r_{vi} - \\\\mu_v) / \\\\sigma_v} {\\\\sum\\\\limits_{v\n",
    "        \\\\in N^k_i(u)} \\\\text{sim}(u, v)}\n",
    "\n",
    "    or\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{r}_{ui} = \\\\mu_i + \\\\sigma_i \\\\frac{ \\\\sum\\\\limits_{j \\\\in N^k_u(i)}\n",
    "        \\\\text{sim}(i, j) \\\\cdot (r_{uj} - \\\\mu_j) / \\\\sigma_j} {\\\\sum\\\\limits_{j\n",
    "        \\\\in N^k_u(i)} \\\\text{sim}(i, j)}\n",
    "\n",
    "    depending on the ``user_based`` field of the ``sim_options`` parameter.\n",
    "\n",
    "    If :math:`\\\\sigma` is 0, than the overall sigma is used in that case.\n",
    "\n",
    "    Args:\n",
    "        k(int): The (max) number of neighbors to take into account for\n",
    "            aggregation (see :ref:`this note <actual_k_note>`). Default is\n",
    "            ``40``.\n",
    "        min_k(int): The minimum number of neighbors to take into account for\n",
    "            aggregation. If there are not enough neighbors, the neighbor\n",
    "            aggregation is set to zero (so the prediction ends up being\n",
    "            equivalent to the mean :math:`\\\\mu_u` or :math:`\\\\mu_i`). Default is\n",
    "            ``1``.\n",
    "        sim_options(dict): A dictionary of options for the similarity\n",
    "            measure. See :ref:`similarity_measures_configuration` for accepted\n",
    "            options.\n",
    "        verbose(bool): Whether to print trace messages of bias estimation,\n",
    "            similarity, etc.  Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=40, min_k=1, sim_options={}, verbose=True, **kwargs):\n",
    "\n",
    "        SymmetricAlgo.__init__(self, sim_options=sim_options, verbose=verbose, **kwargs)\n",
    "\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        SymmetricAlgo.fit(self, trainset)\n",
    "\n",
    "        self.means = np.zeros(self.n_x)\n",
    "        self.sigmas = np.zeros(self.n_x)\n",
    "        # when certain sigma is 0, use overall sigma\n",
    "        self.overall_sigma = np.std([r for (_, _, r) in self.trainset.all_ratings()])\n",
    "\n",
    "        for x, ratings in self.xr.items():\n",
    "            self.means[x] = np.mean([r for (_, r) in ratings])\n",
    "            sigma = np.std([r for (_, r) in ratings])\n",
    "            self.sigmas[x] = self.overall_sigma if sigma == 0.0 else sigma\n",
    "\n",
    "        self.sim = self.compute_similarities()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible(\"User and/or item is unknown.\")\n",
    "\n",
    "        x, y = self.switch(u, i)\n",
    "\n",
    "        neighbors = [(x2, self.sim[x, x2], r) for (x2, r) in self.yr[y]]\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[1])\n",
    "\n",
    "        est = self.means[x]\n",
    "\n",
    "        # compute weighted average\n",
    "        sum_sim = sum_ratings = actual_k = 0\n",
    "        for (nb, sim, r) in k_neighbors:\n",
    "            if sim > 0:\n",
    "                sum_sim += sim\n",
    "                sum_ratings += sim * (r - self.means[nb]) / self.sigmas[nb]\n",
    "                actual_k += 1\n",
    "\n",
    "        if actual_k < self.min_k:\n",
    "            sum_ratings = 0\n",
    "\n",
    "        try:\n",
    "            est += sum_ratings / sum_sim * self.sigmas[x]\n",
    "        except ZeroDivisionError:\n",
    "            pass  # return mean\n",
    "\n",
    "        details = {\"actual_k\": actual_k}\n",
    "        if actual_k == 0:\n",
    "            return est, details, -1, -1\n",
    "        else: \n",
    "            return est, details, sum_sim/actual_k, actual_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "train_raw = pd.read_csv(\"trainset_rate.csv\")\n",
    "train_matrix = pd.read_csv(\"trainset_matrix.csv\")\n",
    "test_rate = pd.read_csv(\"testset_rate.csv\")\n",
    "\n",
    "train_rate = train_raw[train_raw.userId.isna()==False]\n",
    "lost_rate = train_raw[train_raw.userId.isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise Input\n",
    "reader = Reader(rating_scale=(0.5,5))\n",
    "trainset = Dataset.load_from_df(train_rate[1:100000:100],reader=reader)\n",
    "trainset = trainset.build_full_trainset()\n",
    "anti_train = trainset.build_anti_testset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\"msd\",\"cosine\",\"pearson\",\"pearson_baseline\"]\n",
    "user_based_list = [True, False]\n",
    "method_list = [\"KNNBasic\",\"KNNWithMeans\",\"KNNBaseline\",\"KNNWithZScore\"]\n",
    "k = 40\n",
    "for method in method_list:\n",
    "    for name in name_list:\n",
    "        for user_based in user_based_list:\n",
    "            sim_options = {'name': name, 'user_based': user_based}\n",
    "            if method == \"KNNBasic\":\n",
    "                algo = KNNBasic(sim_options=sim_options, k=k)\n",
    "            elif method == \"KNNWithMeans\":\n",
    "                algo = KNNWithMeans(sim_options=sim_options, k=k)\n",
    "            elif method == \"KNNBaseline\":\n",
    "                algo = KNNBaseline(sim_options=sim_options, k=k)\n",
    "            else:\n",
    "                algo = KNNWithZScore(sim_options=sim_options, k=k)\n",
    "            algo.fit(trainset)\n",
    "            print(\"Similartiy:\", name)\n",
    "            print(\"User Based:\", user_based)\n",
    "\n",
    "            # Imputation\n",
    "            predictions = algo.test(anti_train,True)\n",
    "            pred_raw = pd.DataFrame(predictions,\\\n",
    "                        columns=[\"userId\",\"movieId\",\"rating\",\"similarity\",\"neighbors\"])\n",
    "            pred_raw.sort_values(by=[\"similarity\",\"neighbors\"],\\\n",
    "                                 ascending=False,inplace=True)\n",
    "            filename = f\"output\\PredRaw_{method}_{name}Simi_userBased{user_based}_k{k}.csv\"\n",
    "            pred_raw.to_csv(filename,index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
